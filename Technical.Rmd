---
title: "Stock Tools"
author: "Stephen Synchronicity"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
always_allow_html: yes
header-includes:
   - \usepackage{dcolumn}
output: 
  html_document: 
    self_contained: yes
    css: C:\Users\Stephen\Documents\R\win-library\3.4\neuhwk\rmarkdown\templates\report\resources\bootstrap.min.css
    highlight: zenburn
    keep_md: no
    theme: spacelab
    toc: yes
    toc_float: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE,warning=FALSE,cache=TRUE, fig.align='center', fig.height=3.5, fig.width=5, tidy=TRUE, tidy.opts=list(width.cutoff=80))
# rmarkdown::html_dependency_jquery()
# rmarkdown::html_dependency_bootstrap("spacelab")
# rmarkdown::html_dependency_jqueryui()
set.seed(1)
options(scipen=12)
HDA::startPkgs(c("tidyverse","dplyr","htmltools","magrittr","QuantTools","quantmod","lubridate", "rlang"))
# Monitoring ticker data can be accomplished through the IEX API. The following R Script has built in API calls for R.
#source("iex.R")
```

# Objectives
<ol>
  <li>To develop a tax sensitive patterned trading algorithm that does not exceed a tax bracket for a given year.</li>
  <li>To generate at least 10% annual returns.</li>
  <li>To develop a workflow that rapidly transforms OHLC into an indicator rich xts or tbl_time</li>
  <li>To outperform the following benchmark strategies on any single position:<ul>
    <li>The 12,26,9 MACD</li>
    <li>The 14 RSI</li>
    <li>Buy & Hold</li>
  </ul> </li>
  <li>To optimize the portfolio as a whole according to the following three ratios:<ul>
    <li>Sharpe Ratio $\frac{\text{mean return}}{\text{volatility}}$</li>
    <li>Information Ratio $\frac{\text{Annualized Return}{\text{Annualized Risk}}$</li>
    <li>Profit factor: $\frac{\text{Gross Profit}}{\text{Gross Losses}}$ </li>
  </ul> </li>
</ol>

```{r 'Load Data'}
# ----------------------- Sat Mar 24 08:17:41 2018 ------------------------#
# Inputs: Timeseries data, Lag for LM
# Outputs: Coefficient - Derivative
# Use ADX http://www.stockcharts.com/school/doku.php?id=chart_school:technical_indicators:average_directional_index_adx
# Use Parabolic SAR http://www.stockcharts.com/school/doku.php?id=chart_school:technical_indicators:parabolic_sar
# Use RSI http://www.stockcharts.com/school/doku.php?id=chart_school:technical_indicators:relative_strength_index_rsi
# Create Neural net signal tracker
# ----------------------- Mon Aug 06 16:36:13 2018 ------------------------#
# Load my personal portfolio and watch list
googlesheets::gs_auth(token = "~//R//sholsen_googlesheets_token.rds")
gsPositions <- googlesheets::gs_url("https://docs.google.com/spreadsheets/d/1Iazn6lYRMhe-jdJ3P_VhLjG9M9vNWqV-riBmpvBBseg/edit#gid=0")
Positions <- googlesheets::gs_read(gsPositions,ws=1)
# ----------------------- Tue Jun 26 13:52:59 2018 ------------------------#
# Import Dad's portfolio
#Dad.positions <- googlesheets::gs_read(gsPositions,ws=2)
```
```{r 'Clean Data for IEX Requests'}
Positions_v <- Positions[-c(1,2),1,drop=T] # Call for vector of positions
#Dad.positions_v <- Dad.positions[-c(1),1,drop=T]
```
  


<a href="https://iextrading.com/developer/docs/#chart" target="_blank">IEX Documentation: Charts</a>
```{r 'IEX Functions and Chart Fields'}
iex_fields <- tibble::tribble(
  ~field, ~type, ~desc,
               "high",  "number",                                                                                                 "is available on all charts.",
               "low", "number",                                                                                                "is available on all charts.",
            "volume", "number",                                                                                                "is available on all charts.",
             "label", "number",  "is available on all charts. A variable formatted version of the date depending on the range. Optional convienience field.",
    "changeOverTime", "number", "is available on all charts. Percent change of each interval relative to first value. Useful for comparing multiple stocks.",
              "date", "string",                                                                                                "is available on all charts.",
              "open", "number",                                                                                                "is available on all charts.",
             "close", "number",                                                                                                "is available on all charts.",
  "unadjustedVolume", "number",                                                                                              "is not available on 1d chart.",
            "change", "number",                                                                                              "is not available on 1d chart.",
     "changePercent", "number",                                                                                              "is not available on 1d chart.",
              "vwap", "number",                                                                                              "is not available on 1d chart."
  )

```


## Financials
```{r 'Responses per Query Type for Filtering Purposes'}
# ----------------------- Fri Jun 29 18:52:46 2018 ------------------------#
# The IEX API has similarily formatted API calls of the following types:
# stats, quote, earnings, financials
# Each of the types has specific response variables that can be filtered - these are found in the table below.

library("rvest")
iex_responses <- list()
iex_responses$stats <- html_table(read_html("https://iextrading.com/developer/docs/#key-stats") %>% html_node(xpath = "/html/body/div[2]/div[2]/table[18]"))
iex_responses$quote <- html_table(read_html("https://iextrading.com/developer/docs/#key-stats") %>% html_node(xpath = "/html/body/div[2]/div[2]/table[27]"))
iex_responses$earnings <- html_table(read_html("https://iextrading.com/developer/docs/#key-stats") %>% html_node(xpath = "/html/body/div[2]/div[2]/table[11]"))
iex_responses$financials <- html_table(read_html("https://iextrading.com/developer/docs/#key-stats") %>% html_node(xpath = "/html/body/div[2]/div[2]/table[13]"))
```

```{r 'Financial Stats'}
# ----------------------- Wed Aug 08 17:13:33 2018 ------------------------#
# Create a Data frame of financial metrics using IEX

quotes <- iex_stock_req(tSymbols = Positions_v,type = "quote", query_filter = c("marketCap","peRatio","week52High","week52Low","ytdChange"))
stats <- iex_stock_req(tSymbols = Positions_v,type = "stats", query_filter = c("peRatioHigh","peRatioLow","week52change	","returnOnEquity","consensusEPS","ttmEPS","profitMargin","year5ChangePercent","year1ChangePercent","ytdChangePercent","month6ChangePercent","month3ChangePercent","month1ChangePercent","cash","debt"))
fin_stats <- cbind(quotes,stats)

```

```{r 'Batch Symbol Timeseries Data Request'}
#Positions_ts <- lapply(Positions_v, function(x)Riex::iex.chart(x, "5y", iex_sk = keyring::key_get("IEX")))
Positions_ts <- iex_batch_req(tSymbols = Positions_v, range = "5y", filter = iex_fields[c(1:3,6:8,10:11),1,drop=T])
#Dad.positions_ts <- iex_batch_req(tSymbols = Dad.positions_v, range = "1y", filter = iex_fields[c(1:3,6:8,10:11),1,drop=T]) 
```

 
```{r 'Add Sign indicator_Change Date'}
# ----------------------- Tue Jun 26 14:54:21 2018 ------------------------#
# Add sign indicator for color change in candlestick graph 

Positions_ts %<>% lapply(FUN=function(l){
  l$chg <- sign(as.numeric(l$changePercent)) %>% as.character() %>% as.factor()
  l})
# Dad.positions_ts %<>% lapply(FUN=function(l){
#   l$chg <- sign(as.numeric(l$changePercent)) %>% as.character() %>% as.factor()
#   l})

```
```{r 'Rename to Upper' , eval = F}
Positions_ts %<>% lapply(function(l){
  names(l) %<>% str_to_title() 
  return(l)
})
```
```{r 'Rename to lower'}
Positions_ts %<>% lapply(function(l){
  names(l) %<>% tolower() 
  return(l)
})
```
```{r 'Fill Dates for Proper Windowing'}
Positions_ts %<>% purrr::map2(.y = names(.), function(.x, .y){ # Actual Time for measuring exact weeks, quarters and approx. months
out <- xts(order.by = seq(min(time(.x)), max(time(.x)), by = "1 days")) %>% merge.xts(l) %>% na.locf()
xtsAttributes(out) <- list(Sym = .y)
return(out)
})

```

```{r 'Add Risk Metrics'}
Positions.scaled_ts <- lapply(Positions_ts,FUN = function(l){l$close %<>% scale %>% as.numeric
  l})
key_stats <- lapply(seq_along(Positions.scaled_ts), pos=Positions.scaled_ts,timeframe = "year", FUN = function(l,pos,timeframe){
if(!is.null(timeframe) & any(class(pos[[1]])=="data.frame")){
  data <- pos[[l]] %>% filter(date > lubridate::floor_date(lubridate::today(), unit = timeframe))
}else if(!is.null(timeframe) & any(class(pos[[1]])=="xts")){
  data <- pos[[l]][time(pos[[l]]) > lubridate::floor_date(lubridate::today(),timeframe),]
}else {
  data <- pos[[l]]
}
data$ind <- 1:nrow(data)
mod <- lm(close ~ ind, data = data)
out <- vector("numeric",length = 4)
out[1] <- mod[["coefficients"]][["ind"]]
out[2] <- caret::RMSE(mod[["fitted.values"]],mod[["model"]][["close"]])
mod_sum <- summary(mod)
out[3] <- mod_sum %>% {.[["adj.r.squared"]]}
out[4] <- sum(sign(mod_sum[["residuals"]]) < 0)/length(mod_sum[["residuals"]])
out[5] <- (mod_sum[["sigma"]] + mean(abs(mod_sum[["residuals"]][mod_sum[["residuals"]] < 0]),na.rm = T)) / pos[[l]][nrow(pos[[l]]),"open"]
names(out) <- c("coef","rmse","adj.r","pctNeg","sigma")
return(out)
})
names(key_stats) <- names(Positions.scaled_ts)
key_stats %<>% do.call("rbind",.) # From list to dataframe
```

```{r 'Combine & Financial Stats'}
fin_stats_complete <- cbind(key_stats,fin_stats) %>% as.data.frame
DT::datatable(fin_stats_complete)
```

## Statistical Signficance Indicator
```{r 'Two Sigma Indicator'}
# Needs 95% significance uptrend from 200day SMA
sig <- function(.,v){
  sapply(.,v=.,FUN=function(.,v)pnorm(.,mean(v),sd=sd(v)),simplify = "array")
}

map_lgl(seq_along(Dad.positions_ts),pos = Dad.positions_ts,.f=function(l,pos){
  rollapply()
thr <- qnorm(1.1,mean(pos[[l]][,"open",]),sd(pos[[l]][,"open"]))
any(pos[[l]][,"open"] > thr)
  })
```



## Candlestick Graphs
### SEP IRA 
```{r 'Charts for SEP IRA'}
# ----------------------- Tue Jun 26 14:15:19 2018 ------------------------#
# Try with ggplot2 & plotly
# ----------------------- Mon Nov 19 08:54:35 2018 ------------------------#
# BUG(arguments imply differing number of rows: 251, 0) 

Dad.positions_df <- lapply(Dad.positions_ts,function(l){
out <- as.data.frame(l)
out$date <- row.names(out) %>% lubridate::ymd()
return(out)
})
dad_pos_ggp <- lapply(seq_along(Dad.positions_ts),pos = Dad.positions_ts,FUN=function(l,pos){
  pos[[l]] %>% 
  ggplot(data= ., aes(x=date, colour = chg)) +
  theme_bw() +
  geom_linerange(aes(ymin=low, ymax=high)) +
  geom_segment(aes(y = open, yend = open, xend = date - {as.numeric(periodicity(date)[1])} / 2 )) +
  geom_segment(aes(y = close, yend = close, xend = date + {as.numeric(periodicity(date)[1])} / 2)) +
  geom_smooth(method = "lm",aes(y = close))+
  #geom_text(aes(x = lmeq_x, y = lmeq_y, label = lm_eqn(l)), parse = TRUE) +
  scale_colour_manual(values = c("-1" = "darkred", "1" = "darkgreen", "0" = "gray")) + theme(legend.position='none') + 
    labs(title = names(pos)[l],
    subtitle = "1 Year Historical",
    caption = "",
    x = "Date",y = "Closing Price") +
    theme(plot.title = element_text(hjust = .5),plot.subtitle = element_text(hjust = .5))
    
})

lapply(dad_pos_ggp,FUN=function(ggp){plotly::ggplotly(ggp, dynamicTicks = T, tooltip = c("y","high","low"))}
)
```

### Individual
```{r 'Charts for Individual Portfolio'}
pos_ggp <- lapply(seq_along(pos),pos = pos,FUN=function(l,pos){
  pos[[l]] %>% 
  ggplot(data= ., aes(x=date, colour = chg)) +
  theme_bw() +
  geom_linerange(aes(ymin=low, ymax=high)) +
  geom_segment(aes(y = open, yend = open, xend = date - {as.numeric(periodicity(date)[1])} / 2 )) +
  geom_segment(aes(y = close, yend = close, xend = date + {as.numeric(periodicity(date)[1])} / 2)) +
  geom_smooth(method = "lm",aes(y = close))+
  #geom_text(aes(x = lmeq_x, y = lmeq_y, label = lm_eqn(l)), parse = TRUE) +
  scale_colour_manual(values = c("-1" = "darkred", "1" = "darkgreen", "0" = "gray")) + theme(legend.position='none') + 
    labs(title = names(pos)[l],
    subtitle = "1 Year Historical",
    caption = "",
    x = "Date",y = "Closing Price") +
    theme(plot.title = element_text(hjust = .5),plot.subtitle = element_text(hjust = .5))
    
})

lapply(pos_ggp,FUN=function(ggp){plotly::ggplotly(ggp, dynamicTicks = T, tooltip = c("y","high","low"))}
)
```





# Signals & Indicators
## Response Variables
<p>The response variables of interest currently are:
<ul>
<li> the percent change for varying periods of time </li>
<li> the percent of days of the time period in which gains were recognized</li>
<li> the sd for the same time periods </li>
</ul>
</p>
Set the windows:
```{r 'Set Windows'}
wind  <-  c(weeks = 7, months = 7*4, quarters = 7*4*3)
```
<button class="btn btn-sm btn-success" href="#sma" role="button" data-toggle="collapse" data-target="#demo">View Simple Moving Averages</button>
<div id="sma" class="collapse">
```{r 'Add SMA'}
Positions_ts %<>% lapply(wind = c(wind,200) , function(l, wind){
  if (all(!is.na(l[,c("high","low","close")])) ) {
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
    out_sma <- purrr::map(.x = wind[sum(!is.na(l[,"close"])) > wind], l = l, function(.x, l){
      out <- TTR::SMA(l[,c("close")], .x)
      for (i in which(is.na(out))) {
        out[i] <- mean(l[1:i,"close", drop = T])
      }
      names(out) <- paste(names(out), .x, sep = ".") 
      return(out)
    }) 
    out_sma <- do.call("cbind", out_sma)
    if (stringr::str_which(names(l), "SMA\\.\\d{1,2}") %>% length > 0) l <- l[,-stringr::str_which(names(l), "SMA\\.\\d{1,2}")]
    out <- cbind(l, out_sma) 
    } else out <- l
  return(out)
}) 
```
</div>

### Add ADX
<button class="btn btn-sm btn-success" href="#ADX" role="button" data-toggle="collapse" data-target="#demo">View ADX</button>
<div id="adx" class="collapse">
```{r 'Add ADX'}
Positions_ts %<>% lapply(wind = wind, function(l, wind){
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
  if (all(!is.na(l[,c("high","low","close")])) ) {
    adx <- purrr::map(.x = wind[sum(!is.na(l[,"close"])) > wind], l = l, function(.x, l){
      out <- TTR::ADX(l[,c("high","low","close")], .x)
      names(out) <- paste(names(out), .x, sep = ".") 
      return(out)
    }) 
    adx <- do.call("cbind", adx)
    out <- cbind(l, adx) %>% na.locf(fromLast = T)
  }
  else out <- l
  return(out)
}) 
```

```{r 'Compress ADX'}
Positions_ts %<>% lapply(wind = wind, compress = T, function(l, wind, compress){
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
  if (all(!is.na(l[,c("high","low","close")])) ) {
    adx <- purrr::map(.x = wind[sum(!is.na(l[,"close"])) > wind], env = parent.frame(), function(.x, env){
      out <- TTR::ADX(l[,c("high","low","close")], .x) %>% na.locf(fromLast = T)
      if (compress) {
        out <- apply(out, 1, function(r){
          out <- r[["DIp"]] - r[["DIn"]] * log(ifelse(is.na(r[["ADX"]]),r[["DX"]],r[["ADX"]]))
        }) %>% xts::as.xts(order.by = time(l))
        colnames(out) <- paste("ADXc", .x, sep = ".")
      }else {colnames(out) <- paste(colnames(out), .x, sep = ".")}
      return(out)
    }) 
    adx <- do.call("cbind", adx)
    l <- l[,-grep("^ADX|DI\\w.*\\d$",names(l))]
    out <- cbind(l, adx) 
  }
  else out <- l
  return(out)
}) 
l %>% names
lm(months_rv ~ ADXc.28,data = Positions_ts$GOOG) %>% summary
l %>% as.data.frame %>% rownames_to_column("Date") %>% mutate_at(vars("Date"),lubridate::ymd) %>% ggplot(data = .,mapping = aes(x = Date))+
geom_line(aes(y = close), color = HDA::ggColor(3)[1]) + 
  geom_line(aes(y = ADXc.28), color = HDA::ggColor(3)[2]) +
  geom_line(aes(y = months_rv), color = HDA::ggColor(3)[3])

```

<strong>Uptrend</strong>
[type = stock] AND [country = US] 
AND [Daily SMA(20,Daily Volume) > 100000] 
AND [Daily SMA(60,Daily Close) > 10] 

AND [Daily ADX Line(14) > 20] 
AND [Daily Plus DI(14) crosses Daily Minus DI(14)] 
AND [Daily Close > Daily SMA(50,Daily Close)]

<strong>Downtrend</strong>
[type = stock] AND [country = US] 
AND [Daily SMA(20,Daily Volume) > 100000] 
AND [Daily SMA(60,Daily Close) > 10] 

AND [Daily ADX Line(14) > 20] 
AND [Daily Minus DI(14) crosses Daily Plus DI(14)] 
AND [Daily Close < Daily SMA(50,Daily Close)]

```{r 'Add ADX Signal'}
Positions_ts %<>% lapply(threshold1 = 20, threshold2 = 25, wind = wind, verbose = F, function(l, threshold1, threshold2, wind, verbose){
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
  if (all(!is.na(l[,c("high","low","close")]))  ) {
    out <- list()
    for (i in seq_along(wind[sum(!is.na(l[,"close"])) > wind])) {
      cls <- c(paste0(c("ADX.","DIp.","DIn.","DX.","SMA."), wind[i]),"close")
      out[[i]] <- apply(l[,cls], 1, function(r, env = parent.frame()){
        if (any(is.na(r))) {return("0")} # Check for NA and return none if present
        if (r[[cls[1]]] > threshold1 & r[[cls[2]]] > r[[cls[3]]] & r[["close"]] > r[[cls[4]]]) {
          return("1") # Moderate uptrend
        }else if (r[[cls[1]]] > threshold2 & r[[cls[2]]] > r[[cls[3]]] & r[["close"]] > r[[cls[4]]]) {
          return("2") # Strong uptrend
        }else if (r[[cls[1]]] > threshold1 & r[[cls[2]]] < r[[cls[3]]] & r[["close"]] < r[[cls[4]]]) {
          return("-1") # Moderate Downtrend
        }else if (r[[cls[1]]] > threshold2 & r[[cls[2]]] < r[[cls[3]]] & r[["close"]] < r[[cls[4]]]) {
          return("-2") # Strong downtrend
        } else return("0")
        if (verbose == T) print(time(r))
      })
    }
  } else return(l)
  nms <- paste0("ADX.", wind, "_i")
  out <- do.call("cbind", out) %>% xts(order.by = time(l))
  colnames(out) <- nms
  if (verbose == T) print(identical(time(out), time(l)))
  out <- cbind.xts(l, out)
  if (verbose == T) print(nrow(out))
  return(out)
  
})
```
</div>
```{r}
Positions_ts %>% purrr::map(function(l){
  names(l)[stringr::str_which(names(l),"\\.1$")] %>% str_replace("\\.1$","")
})
```

## Add Variables in Article
Referencing: <a href="https://www.quantinsti.com/blog/predictive-modeling-algorithmic-trading/">R Predictive Algorithm</a>
### Add Williams %R
<button class="btn btn-sm btn-success" href="#wpr" role="button" data-toggle="collapse" data-target="#demo">View Williams %R</button>
<div id="wpr" class="collapse">
```{r 'Add Williams Indicator'}
# ----------------------- Fri May 04 10:35:38 2018 ------------------------#
# Add the Williams %R where per = vector of period lengths.
Positions_ts %<>% lapply(wind = c(7, 7*4, 7*4*3), verbose = F, function(l, wind, verbose){
  if (nrow(l) > max(wind)) message("Number of observations is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations.")
  if (all(!is.na(l[,c("high","low","close")])) ) {
    WpR <- purrr::map(.x = wind[sum(!is.na(l[,"close"])) > wind], function(.x, env = parent.frame()){
      out <- TTR::WPR(l[,c("high","low","close")],n = .x)
      for (i in which(is.na(out))) {
        hmax <- max(l[1:i,"high"])
        if (verbose) print(hmax)
        lmin <- min(l[1:i,"low"])
        if (verbose) print(lmin)
        pctR <- ifelse({(hmax - l[i,"close"])/(hmax - lmin)} %>% is.nan, 0.5, (hmax - l[i,"close"])/(hmax - lmin))
        out[i] <- pctR
      }
      return(out)
    })
    if (verbose) print(WpR)
    WpR <- do.call("cbind", WpR)
    colnames(WpR) <- paste("WpR", wind[sum(!is.na(l[,"close"])) > wind], sep = ".")
    if (stringr::str_which(names(l),"^WpR\\.\\d{1,2}") %>% length > 0) l <- l[,-c(stringr::str_which(names(l),"^WpR\\.\\d{1,2}"))]
    out <- cbind(l,WpR) }
  else out <- l
  return(out)
})
```
</div>

### Add Relative Strength Indicator
<button class="btn btn-sm btn-success" href="#rsi" role="button" data-toggle="collapse" data-target="#demo">View RSI</button>
<div id="rsi" class="collapse">
```{r 'Add RSI'}
rsi_wind <- c(7, 14)
Positions_ts %<>% lapply(wind = rsi_wind, verbose = F, function(l, wind, verbose){
  if (nrow(l) > max(wind)) message("Number of observations is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations.")
  if (all(!is.na(l[,c("high","low","close")])) ) {
    rsic <- purrr::map(wind[sum(!is.na(l[,"close"])) > wind], l = l, function(.x, l){
      out <- TTR::RSI(l[,c("close")], n = .x)
      out <- na.locf(out, fromLast = T)
      return(out)
    })
    if (verbose == T) any(is.na(rsic)) %>% print
    rsic <- do.call("cbind", rsic)
    colnames(rsic) <- paste("rsi", wind, sep = ".")
    if (grep("^rsi\\.\\d{1,2}$",names(l)) %>% length > 0) l <- l[, -grep("^rsi\\.\\d{1,2}$",names(l))]
    out <- cbind(l,rsic)
  } else out <- l
  return(out)
})
```

<strong>Oversold in Uptrend</strong>
[type = stock] AND [country = US] 
AND [Daily SMA(20,Daily Volume) > 40000] 
AND [Daily SMA(60,Daily Close) > 20] 

AND [Daily Close > Daily SMA(200,Daily Close)] 
AND [Daily RSI(5,Daily Close) <= 30]
<strong>RSI Overbought in Downtrend</strong>
[type = stock] AND [country = US] 
AND [Daily SMA(20,Daily Volume) > 40000] 
AND [Daily SMA(60,Daily Close) > 20] 

AND [Daily Close < Daily SMA(200,Daily Close)] 
AND [Daily RSI(5,Daily Close) >= 70]
```{r 'Add RSI Indicator',eval=F}
# 
# ----------------------- Tue Apr 24 11:26:17 2018 ------------------------#
# Needs refinemnt of factor indicators
Positions_ts %<>% lapply(wind = rsi_wind, threshold1 = c(high = 70, low = 30), threshold2 = c(high = 80, low = 20), verbose = F, function(l, wind, threshold1, threshold2, verbose){
  if (nrow(l) > max(wind)) message("Number of observations is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations.")
  if (all(!is.na(l[,c("high","low","close")])) ) {
    out <- list()
    for (i in seq_along(wind[sum(!is.na(l[,"close"])) > wind])) { # Up to the second to last window
      cls <- c(paste0(c("rsi."), wind[i]), "SMA.200","close")
      out[[i]] <- apply(l[,cls], 1, function(r, env = parent.frame()){
        if (any(is.na(r))) {return("0")} # Check for NA and return none if present
        if (r[[cls[1]]] < threshold1["low"] & r[[cls[2]]] < r[["close"]] ) {
          return("-1") # Moderate oversold
        }else if (r[[cls[1]]] < threshold2["low"] & r[[cls[2]]] < r[["close"]]) {
          return("-2") # Strong oversold
        }else if (r[[cls[1]]] > threshold1["high"] & r[[cls[2]]] > r[["close"]]) {
          return("1") # Moderate overbought
        }else if (r[[cls[1]]] > threshold2["high"] & r[[cls[2]]] > r[["close"]]) {
          return("2") # Strong overbought
        } else return("0")
        if (verbose == T) print(time(r))
      })
    }
    nms <- paste0("rsi.", wind, "_i")
    out <- do.call("cbind", out) %>% xts(order.by = time(l))
    colnames(out) <- nms
    if (verbose == T) print(identical(time(out), time(l)))
    if (grep("^rsi.*i$",names(l)) %>% length > 0) l <- l[,-grep("^rsi.*i$",names(l))]
    out <- cbind.xts(l, out)
    if (verbose == T) print(nrow(out))
  }else return(l)
  return(out)
})

```
</div>


<button class="btn btn-sm btn-success" href="#roc" role="button" data-toggle="collapse" data-target="#demo">Add Rate of Change and Momentum</button>
<div id="roc" class="collapse">
### Add Rate of Change (ROC) and Momentum
<ul>
  <li><a href="http://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:rate_of_change_roc_and_momentum" target="_blank">ChartSchools: ROC</a></li>
  <li><a href="https://www.investopedia.com/articles/technical/092401.asp" target="_blank">Investopedia: ROC 101</a></li>
</ul>


```{r 'Add ROC and Momentum'}
Positions_ts %<>% lapply(wind = wind, verbose = F, function(l, wind, verbose){
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
  if (all(!is.na(l[,c("high","low","close")])) ) {
    # ROC
    roc <- purrr::map(.x = wind[sum(!is.na(l[,"close"])) > wind], env = parent.frame(),function(.x, env){
      roc <- TTR::ROC(l[,c("close")],n = .x)
      for (i in which(is.na(roc))) {
        roc[i + 1] <- diff(log(l[,c("close")]),i)[i + 1]
      }
      roc[1] <- 0
      return(roc)
    })
    # momentum
    mom <- purrr::map(wind[sum(!is.na(l[,"close"])) > wind], env = parent.frame(), function(.x, env){
      mom <- TTR::momentum(l[,c("close")], n = .x)
      for (i in which(is.na(mom))) {
        mom[i + 1] <- diff(l[,c("close")],i)[i + 1]
      }
      mom[1] <- 0
      return(mom)
    })
    # create  out object
    roc <- do.call("cbind", roc)
    mom <- do.call("cbind", mom)
    if (verbose == T) print(c(nrow(roc),nrow(mom)))
    colnames(roc) <- paste("roc", wind, sep = ".")
    colnames(mom) <- paste("mom", wind, sep = ".")
    out <- cbind.xts(l, roc, mom)
  } else out <- l
  
  
  if (verbose == T) print(nrow(out))
  return(out)
})
```
</div>
### Add Average True Range
<button class="btn btn-sm btn-success" href="#atr" role="button" data-toggle="collapse" data-target="#demo">View ATR</button>
<div id="atr" class="collapse">
<ul>
  <li><a href="http://stockcharts.com/school/doku.php?id=chart_school:technical_indicators:average_true_range_atr" target="_blank">StockCharts: ATR</a></li>
  <li><a href="https://www.investopedia.com/articles/trading/08/average-true-range.asp" target="_blank">Investopedia: Using ATR</a></li>
</ul>
ATR is best used to set a stop loss at the daily low - 1ATR
```{r 'Add ATR'}
# ----------------------- Sat May 05 10:15:47 2018 ------------------------#
# Average True Range could be useful for setting stop-loss
Positions_ts %<>% lapply(wind = sort(c(wind,14)), verbose = F, function(l, wind, verbose){
  if (nrow(l) > max(wind)) message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))
  if (all(!is.na(quantmod::HLC(l))) ) {
    atrs <- purrr::map(wind[sum(!is.na(l[,"close"])) > wind], env = parent.frame(), function(.x, env){
      atr <- TTR::ATR(quantmod::HLC(l), n = .x)
      atr <- na.locf(atr, fromLast = T)
      names(atr) <- names(atr) %>% paste(.x, sep = ".")
      return(atr)
    })
    if (verbose == T) any(is.na(atrs)) %>% print
    atrs <- do.call("cbind", atrs)
    out <- cbind(l,atrs[,c(atrs %>% names %>% grep("atr",.), atrs %>% names %>% grep("trueLow.14",.))])
  } else out <- l
  return(out)
})
```
</div>

### Add SAR
<button class="btn btn-sm btn-success" href="#sar" role="button" data-toggle="collapse" data-target="#demo">View SAR</button>
<div id="sar" class="collapse">

```{r 'Add SAR'}
# ----------------------- Sat May 05 10:15:47 2018 ------------------------#
# Average True Range could be useful for setting stop-loss
Positions_ts %<>% lapply(verbose = F, function(l, verbose){
  if (all(!is.na(quantmod::HLC(l))) ) {
    l <- l[, -grep("sar", names(l), ignore.case = T)]
    sar <- TTR::SAR(quantmod::HLC(l), accel = c(0.05, 0.2))
    if (verbose == T) any(is.na(sar)) %>% print
    out <- cbind(l,sar)
  } else out <- l
  return(out)
})
```
<strong>Break Above Falling SAR</strong>
AND [Yesterday's Daily High < Yesterday's Daily Parabolic SAR(0.01,0.2)] 
AND [Daily High > Daily Parabolic SAR(0.01,0.2)]
<strong>Break Below Rising SAR</strong>
AND [Yesterday's Daily Low > Yesterday's Daily Parabolic SAR(0.01,0.2)] 
AND [Daily Low < Daily Parabolic SAR(0.01,0.2)]
```{r 'Add SAR Indicator'}
Positions_ts %<>% lapply(verbose = F, function(l, verbose){
  
  if (all(!is.na(quantmod::HLC(l))) ) {
    out <- rollapply(l[,grep("high|low|close|sar", names(l), ignore.case = T)], width = 2, align = "right", by.column = F, env = parent.frame(), function(r, env){
      if (verbose == T) print(r)
      # Names of each of the columns
      sar_nm <- grep("sar", names(r), ignore.case = T)
      low_nm <- grep("low", names(r), ignore.case = T)[1]
      high_nm <- grep("high", names(r), ignore.case = T)[1]
      close_nm <- grep("close", names(r), ignore.case = T)[1]
      if (verbose == T) print(c(SAR = sar_nm, Low = low_nm, Hi = high_nm, Cl = close_nm))
      # SAR values
      p_sar <- as.numeric(r[1,sar_nm])
      n_sar <- as.numeric(r[2,sar_nm])
      p_hi <- as.numeric(r[1,high_nm])
      p_lo <- as.numeric(r[1,low_nm])
      n_hi <- as.numeric(r[2,high_nm])
      n_lo <- as.numeric(r[2,low_nm])
      if (p_hi < p_sar & n_hi > n_sar) {return(-1)
      }else if (p_lo > p_sar & n_lo < n_sar) {return(1)
      }else {return(0)} 
    })
    out <- na.locf(out, fromLast = T)
    colnames(out) <- paste0("sar", "_i")
    if (verbose == T) any(is.na(out)) %>% print
    out <- cbind(l,out)
  } else out <- l
  return(out)
})
  
```
```{r 'SAR Tune'}
sarParam_df <- expand.grid(af = c(seq(.01,.2,.01)), mf = c(5,10,20,50)) %>% mutate(maf = af*mf) %>% select(-mf)

```
</div>
<button type="button" data-toggle="collapse" data-target="#macd" class="btn btn-outline-primary">View MACD</button>
<div class="collapse" id="macd">


### Add MACD

```{r 'Add MACD'}
Positions_ts %<>% purrr::map(wind = wind, function(l, wind){
  if (nrow(l) > max(wind)) {message(paste0("Number of observations in", xtsAttributes(l, user = T)," is fewer than maximum window. Outcome will only be calculated for those windows that do not exceed the max number of observations."))}
  wind <- wind[sum(!is.na(l[,"close"])) > wind]
  if (length(wind) < 2) stop("At least two window values must be fewer than the number of observations in the data")
  
  if (all(!is.na(quantmod::HLC(l))) ) {
    macd <- TTR::MACD(quantmod::Cl(l), nFast = wind[1] * 2, nSlow = wind[2], nSig = wind[1], maType = TTR::EMA)
    macd[,"macd"] %<>%  na.locf(fromLast = T)
    macd[,"signal"] %<>% na.locf(fromLast = T)
    macd_dif <- macd[,"macd"] - macd[,"signal"]
    out <- cbind(l, macd_dif)
  } else out <- l
  return(out)
})
```
</div>
## Add Response Variables

```{r 'Input RV Time Periods'}
# ----------------------- Fri Aug 17 15:23:09 2018 ------------------------#
# timeperiods can be in Date: duration format, or number of intra-day observations. ie lubridate::duration(1,"weeks") or lubridate::dweeks(1). 
timeperiods <- c(lubridate::dweeks(1),lubridate::dweeks(2),lubridate::duration(1,"months"))
```

```{r 'Percent Change'}
addpChange <- function(d.f,varnm = "close", wind = 5, verbose = F){
  clos <- d.f[,varnm]
  v <- verbose
dopC  <- lapply(wind,function(tp,cl = clos, verbose = v){
    vout <- sapply(seq_along(cl),win=tp,.cl=cl,.verb=verbose,FUN=function(i,win,.cl,.verb){
   if(lubridate::is.duration(win)!=T){ 
    if(i-win < 1){ind <- 1}else {ind <- i-win} # Cases where the lag falls outside the time window
    if(.verb==T){print(i);print(c(.cl[ind],.cl[i]))}
   }else if(lubridate::is.duration(win)){
     if(time(.cl)[i] - win < time(.cl)[1]){ind <- 1}else {ind <- which(abs(time(.cl)-(time(.cl)[i] - win)) == min(abs(time(.cl) - (time(.cl)[i] - win))))[1]} # Cases where the lag falls outside the time window
      if(.verb==T){print(time(.cl)[i])}
   }
    out <- (.cl[[ind]]-.cl[[i]])/.cl[[ind]]
    if(is.na(out)){out <- 0}
    return(out)
  })
})

  
 if(is.duration(wind)){nm <- paste0("pC",wind %>% str_extract("(?<=\\(\\~)[\\s[:alnum:]\\.]+"))}else{nm <- paste0("pC",wind)}
nm %<>% make.names
  out <- cbind(d.f,do.call("cbind",dopC))
  names(out)[(dim(out)[2]-(length(dopC)-1)):dim(out)[2]] <- nm
  return(out)
}
# ----------------------- Fri Aug 17 15:53:03 2018 ------------------------#
# For Testing
cl <- Positions_ts$GOOG$close
wind <- timeperiods[1]
verbose <- F
addpChange(Positions_ts[[1]],varnm = "close",wind = timeperiods,verbose=F) %>% as.data.frame

```

```{r 'Standard Deviation'}
sDxts <- function(cl,wind = 5,verbose=F){
  vout <- sapply(seq_along(cl),wind=wind,cl=cl,verbose=verbose,FUN=function(i, wind, cl, verbose){
    if(lubridate::is.duration(wind)!=T){
      if(i-wind < 1){ind <- 1}else {ind <- i-wind}
      if(verbose==T){print(i);print(c(cl[ind],cl[i]))}
    }else if(lubridate::is.duration(wind)){
      if(time(cl)[i] - wind < time(cl)[1]){ind <- 1}else {ind <- which(time(cl)[i] - wind == time(cl))}
      if(verbose==T){time(cl)[i]}
    }
  cl %<>% scale
  out <- sd(cl[c(seq(i,ind))],na.rm = T)
  if(is.na(out)){out <- 0}
return(out)
  })
}
# test <- sd.xts(cl,wind,F)
```

```{r 'Percent Rise'}
pRise <- function(cl,wind,verbose=F){
  vout <- sapply(seq_along(cl),wind=wind,cl=cl,verbose=verbose,FUN=function(i,wind,cl,verbose){
    if(i==1){return(0)} # Account for a single day that will error diff
    if(lubridate::is.duration(wind)!=T){
      if(i-wind < 1){ind <- 1}else {ind <- i-wind}
      if(verbose==T){print(i);print(c(cl[ind],cl[i]))}
    }else if(lubridate::is.duration(wind)){
      if(time(cl)[i] - wind < time(cl)[1]){ind <- 1}else {ind <- which(time(cl)[i] - wind == time(cl))}
      if(verbose==T){time(cl)[i]}
    }
   out <- cl[c(seq(i,ind))] %>% rev() %>% diff() %>% sign() %>% table() %>% prop.table() %>% .["1"]
   if(is.na(out)){return(0)} # Account for no rise
    return(out)
   # Get the values in the window. Because seq is in reverse, the values need to flipped with rev. Take the diff, get the sign of the difference, table that, then give proportions, assign the proportion associated with positive gains.
   
  })
}
#test <- pRise(cl,wind,verbose=F)
```

```{r 'addRV Meta Function'}
# ----------------------- Sat Aug 18 07:44:32 2018 ------------------------#
# This Function accepts an input of the types of RVs and adds them to the list of timeseries rather than running each chunk individually.

test <- lapply(Positions_ts,rv = c("pChange","pRise","sd"), tp = timeperiods, FUN = function(l,rv,tp, verbose = F){
vout <- list()
# ----------------------- Sat Aug 18 07:12:17 2018 ------------------------#
# percent Change
if(any(rv == "pChange")){
vout$pChanges <- sapply(tp,l=l,verbose=verbose,FUN = function(x,l,verbose){
    pChange(l$close,x,verbose)
  })
}
# ----------------------- Sat Aug 18 07:12:02 2018 ------------------------#
# percent Rise
if(any(rv == "pRise")){
vout$pRise <- sapply(tp,l=l,verbose=verbose,FUN = function(x,l,verbose){
    pRise(l$close,x,verbose)
  })
}
# ----------------------- Sat Aug 18 07:13:12 2018 ------------------------#
# Standard Deviation
  if(any(rv == "sd")){
vout$sd <- sapply(tp,l=l,verbose=verbose,FUN = function(x,l,verbose){
    sDxts(l$close,x,verbose)
  })
}
# Label all columns
vout <- lapply(seq_along(vout),tp = tp, nms = names(vout),vout=vout, FUN = function(o,tp,nms,vout){
  if(lubridate::is.duration(tp)){tp <- timeperiods %>% as.character() %>% stringr::str_extract("((?<=\\~)[\\.A-Za-z0-9\\s]+)") %>% gsub(" ","",.)}
  colNames <- sapply(tp,nm = nms[o],FUN = function(x,nm){
    paste0(nm,".", x)
  })
  colnames(vout[[o]]) <- colNames
  return(vout[[o]])
})
rvs <- do.call("cbind",vout)
l <- cbind(l,rvs)
})
```

# Add Response Variable Trailing Stop Loss
```{r 'Test Trailing Stop Loss Fn'}
source("Jobs & Scripts/QuantFunctions_TSL.R")
rstudioapi::jobRunScript("Jobs & Scripts/TestTSL.R",workingDir = getwd(), exportEnv = "R_GlobalEnv")
```
```{r 'Add TSL as RV'}
rstudioapi::jobRunScript("Jobs & Scripts/AddTSLRV.R",workingDir = getwd(), exportEnv = "R_GlobalEnv")
```


```{r 'Old RV', eval=F}
# ----------------------- Sun May 19 08:33:01 2019 ------------------------#
# Doesnt work properly, error in findPeaks

list(function(x){.1}, .5, function(x){})
Positions_ts %<>% lapply(wind = wind, verbose = T, function(l, wind, verbose){
  dat <- cbind(quantmod::OHLC(l),l[,"sar_i"])
  cl_nm <- grep("close", names(dat), ignore.case = T)
  sa_nm <- grep("sar", names(dat), ignore.case = T)
  if (all(!is.na(dat))) {
    rvs <- purrr::map(wind, env = parent.frame(), function(.x, env){
      if (nrow(dat) <= .x) .x <- {nrow(dat) - 1}
      ras <- zoo::rollapplyr(dat[,c(cl_nm, sa_nm)], width = .x, align = "left", by.column = F, env = parent.frame(), na.pad = T, partial = T, function(r, env){
        if (!is.na(which(r[, 2] == -1)[1])) s <- which(r[, 2] == -1)[1] else s <- numeric(0)
        if(verbose == T) print(s)
        p <- quantmod::findPeaks(r[, 1], thresh = sd(r[1]))
        v <- quantmod::findValleys(r[, 1], thresh = sd(r[1]))
        if (length(s) != 0) i <- s[1] else if (length(p) != 0) i <- p[1] else if (length(v) != 0) i <- v[1] else i <- .x
        if(verbose == T) print(i)
        out <- {coredata(r[i, 1]) - coredata(r[1, 1])}
        if(verbose == T) print(out)
        return(out)
      })
      # Fill the NA at the end
      na_ind <- which(is.na(ras)) 
      n <- min(na_ind)
      end <- max(na_ind)
      while (n < end) {
        # Use the SAR as the Sell point first, Which returns index within n:na_ind, so to get the actual index it needs to be used as a subset of n:end
        if (!is.na(which(dat[n:end, sa_nm] == -1)[1])) s <- c(n:end)[which(dat[n:end, sa_nm] == -1)[1]] else s <- numeric(0)
        p <- c(n:end)[quantmod::findPeaks(dat[n:end, cl_nm], thresh = sd(dat[n:end, cl_nm]))]
        v <- c(n:end)[quantmod::findValleys(dat[n:end, cl_nm], thresh = sd(dat[n:end, cl_nm]))]
        if(verbose == T) print(c(s=s,p=p,v=v))
        if (length(s) != 0) i <- s[1] else if (length(p) != 0) i <- p[1] else if (length(v) != 0) i <- v[1] else i <- end
        if(verbose == T) print(i)
        ras[n] <- {coredata(dat[i, cl_nm]) - coredata(dat[n, cl_nm])}
        n <- n + 1
      }
      ras[n] <- 0
      # END
      return(ras)
    })
  out <- do.call("cbind", rvs)
  colnames(out) <- paste0(names(out), ".","_rv")
  l <- l[,- grep("rv$",names(l))]
  out <- cbind(l, out)
  }else out <- l
  return(out)
})

```

```{r 'Save Data'}
save(Positions_ts, file = paste0("Positions_ts",Positions_ts[[1]] %>% time %>% min,"_",Positions_ts[[1]] %>% time %>% max,".Rdata"))
```





```{r 'Random Forest Variable Importance Filter and xgbTree Prediction'}
rstudioapi::jobRunScript(path = "Jobs & Scripts/RFAttrFilterandxgBoost.R", workingDir = getwd(), importEnv = F,exportEnv = "R_GlobalEnv")
```
```{r 'Examine Models'}
save(Positions_dt, file = paste0("xgBoost",Positions_ts$GOOG %>% time %>% min,"_",Positions_ts$GOOG %>% time %>% max,".Rdata"))
Model_Perf <- parallel::mclapply(Positions_dt, function(dt){
  if(is.null(dt)) return(NULL)
  names(dt) <-  purrr::map(dt, purrr::pluck, "terms", 2) %>% as.character()
  mdl_performance <- rbindlist(purrr::map2(.x = dt, .y = names(dt), function(.x, .y){
    out <- purrr::pluck(.x,"results") %>% mutate(Model = .y)
    return(out)})
  )
  out <- list()
  out$mdl_imp <- purrr::map(.x = dt, function(.x){
    mod <- purrr::pluck(.x,"finalModel")
    out <- list()
    out$mod_imp <- xgboost::xgb.importance(mod[["feature_names"]],mod)
    out$mod_plot <- xgboost::xgb.ggplot.importance(out$mod_imp)
    return(out)
    })
  out$mdl_performance <- mdl_performance %>% mutate(Mod_Rank = percent_rank(Rsquared)) %>% arrange(desc(Mod_Rank))
  return(out)
  })
# Remove training data to create a smaller file
Positions_dt %<>% purrr::map(function(l){
  l[[1]][["trainingData"]] %<>% .[, stringr::str_which(names(.),".outcome|Index")]
  return(l)
})
# Find Correlated Stocks for Backtesting algorithms:
# http://www.sectorspdr.com/sectorspdr/tools/correlation-tracker
```


# Add All Variables to an OOT Dataset
```{r 'Add Vars to OOT'}
rstudioapi::jobRunScript("Jobs & Scripts/AddAllVariablestoNewData.R", workingDir = getwd(), exportEnv = "R_GlobalEnv", importEnv = F)
```





# The closing price column is required. 
<h3>Arguments</h3>
  <table class="R argblock">
    <tbody>
      <tr>
        <td>
          <code>cl</code>
          <td>
            <p>The column with the closing price. Defaults to 'close' <em>Required</em></p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>buy</code>
          <td>
            <p>The column that indicates when a buy occurs. <em>Required</em></p>
          </td>
        </td>
      </tr>
      <tr>
      <tr>
        <td>
          <code>dcol</code>
          <td>
            <p>Column with lagged differences. <em>Required</em></p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>amt <em>Numeric</em></code>
          <td>
            <p>An amount at which the trailing stop will be set</p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>wind <em>Numeric</em></code>
          <td>
            <p> A window of previous periods for which the average difference between close and lo will be calculated, converted to % of bid, and set as the trailing stop.</p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>std <em>Logical</em></code>
          <td>
            <p> Instead of computing the average of the high to low range for the window as the percent trailing stop, calculate the standard deviation of price over a given window, divide by current bid, and use that as the percent.</p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>prcnt (.dd) format<em>Numeric</em></code>
          <td>
            <p>A fixed decimal percent of the bid price for which the stoploss will be calculated.</p>
          </td>
        </td>
      </tr>
      <tr>
        <td>
          <code>lo</code>
          <td>
            <p>The column with the period low price. Defaults to 'low'</p>
          </td>
        </td>
      </tr>
    </tbody>
  </table>  
```{r 'Add Diff column'}

trailStop <- function(cl,buy,dcol,amt=NULL,wind=NULL,std=NULL,prcnt=NULL,hi=NULL,lo=NULL,verbose=F) {
  trail.args <- c(amt=amt,wind=wind,prcnt=prcnt)
  e <- new.env()
  if(all(is.null(trail.args))){stop("One type of value must be specified")}
  if(exists("wind") & not(exists("lo"))){stop("Period low column must be specified")}
  trail.type <- names(trail.args)[which(!is.null(trail.args))]
  vout <- sapply(seq_along(buy),simplify=T,buy=buy,trail.type=trail.type,trail.args=trail.args,cl=cl,dcol=dcol,std=std,lo=lo,hi=hi,FUN=function(i,buy,trail.type,trail.args,cl,lo,hi,dcol,std){
    if(buy[i] == "buy" & trail.type == "wind" & is.null(std) & !is.null(hi)){
      hi.ind <- hi[c(seq(i,i - trail.args[trail.type]))]
      lo.ind <- lo[c(seq(i,i - trail.args[trail.type]))]
      trail <- mean(hi.ind-lo.ind)/cl[i]
      attr(trail,"type") <- "prcnt" # assign the type of the trailing stop
      attr(trail,"i") <- i # assign the pt at which the trailing stop was assigned for creating a cumsum of losses
      assign("trail", trail, envir=e)
    }else if(buy[i] == "buy" & trail.type == "wind" & is.null(std) & is.null(hi)){
      cl.ind <- cl[c(seq(i,i - trail.args[trail.type]))]
      lo.ind <- lo[c(seq(i,i - trail.args[trail.type]))]
      trail <- mean(cl.ind-lo.ind)/cl[i]
      attr(trail,"type") <- "prcnt" # assign the type of the trailing stop
      attr(trail,"i") <- i # assign the pt at which the trailing stop was assigned for creating a cumsum of losses
      assign("trail", trail, envir=e)
    }else if(buy[i] == "buy" & trail.type == "wind" & !is.null(std)){
      cl.ind <- cl[c(seq(i,i - trail.args[trail.type]))]
      trail <- sd(cl.ind)/cl[i]
      attr(trail,"type") <- "prcnt" # assign the type of the trailing stop
      attr(trail,"i") <- i
      assign("trail", trail, envir=e)
      }else if(buy[i] == "buy" & trail.type == "prcnt"){
        trail <- prcnt
        attr(trail,"type") <- "prcnt"
        attr(trail,"i") <- i
        assign("trail", trail, envir=e)
      }else if(buy[i] == "buy" & trail.type == "amt"){
          trail <- amt
          attr(trail,"type") <- "amt"
          attr(trail,"i") <- i
          assign("trail", trail, envir=e)
      }else if(buy[i] == "sell"){
        rm("trail",envir=e)
      }
    out <- "none"
   if(verbose==T){print(i)}
    if(exists("trail",envir=e)){
      trail <- e$trail
      y <- attr(trail,"i")
      cumu <- sum(dcol[seq(i,y)])
    if(verbose==T){print(e$trail)}
    
    if(attr(trail,"type") == "prcnt"){ # Checking Statements
        
         if(cumu < trail*cl[{i-1}]*-1){
           out <- "sell"
           rm("trail",envir=e)}
      }else if(attr(trail,"type") == "amt"){
          if(cumu < trail * -1){
            out <- "sell"
            rm("trail",envir=e)}
      }else {
          out <- "none"
      }
    }else {
          return("none")}
    return(out)
    
    # ----------------------- Thu Apr 26 08:52:37 2018 ------------------------#
    # Need a check on each increment - will need if statement for prcnt type trails (wind,prcnt) and fixed amt
    # Completed(2018-04-26 0913)
  })
  return(vout)
}
#trailStop(cl=TS.adxsar$GOOG$close,buy=TS.adxsar$GOOG$ADXSAR.i,dcol=TS.adxsar$GOOG$Diff,wind=5,lo=TS.adxsar$GOOG$low)
TS.adxsar %<>% lapply(FUN=function(l){
  l %<>% mutate(Diff=c(0,diff(close)),Trail=trailStop(cl=close,buy=ADXSAR.i,dcol=Diff,wind=8,std=T))
})
googleVis::gvisTable(TS.adxsar$GOOG) %>% plot
```

<p>Let's step up the complexity a bit with a machine learning algorithm that takes a lag window as inputs and outputs predictions for price movement.</p>

```{r}
library(caret)
library(caretEnsemble)

data.tr <- dplyr::select(TS.adxsar$GOOG,close,sar,ADXv,DIn,DIp,DX,sar.i,adx.i,pr) %>% mutate(Diff=c(diff(close),0)) %>% na.omit # make the diff of the next day in line with the current day bc that is what needs to be predicted
data.tr %<>% renamena()
data.tr %<>% convert2dummyVars() 

rv <- "Diff" # Name of response variable
req.packages <- c("caret","doParallel","iterators","parallel","foreach") # [package dependencies]
  startPkgs <- Vectorize(FUN=function(pkg){suppressPackageStartupMessages(library(pkg,character.only = T))})
  startPkgs(req.packages)
cl <- makeCluster(detectCores()-1)
  registerDoParallel(cl)
  getDoParWorkers()
  sysT.mod <- system.time({ #[model name]
  data.train <- caret::createDataPartition(data.tr[[rv]], times = 1, p=.85) #[Data] & [y-var]
  data.train <- caret::trainControl(method="repeatedcv",
                             index=data.train, 
                             number=10,
                             repeats=1, 
                             search = "grid",
                             allowParallel = T,
                             returnData = F,
                             returnResamp = "all")
  form <- as.formula(paste0(rv," ~ .")) #[y-var]
  
  mod <- caret::train(form = form, # [model name]
                      data = data.tr,
                      trControl = data.train,
                      metric="RMSE",
                      method = "avNNet",
                      tuneLength = 10)
  })
 
  stopCluster(cl);registerDoSEQ()
```

```{r, 'Predict Diff using Various ML Algorithms', echo=TRUE}
library(caret)
library(caretEnsemble)
data.tr <- renamena(TS.adxsar$GOOG)
data.tr <- dplyr::select(data.tr,close,sar,ADXv,DIn,DIp,DX,sar.i,adx.i,pr) %>% mutate(Diff=c(diff(close),0)) %>% na.omit # make the diff of the next day in line with the current day bc that is what needs to be predicted
data.tr[,sapply(data.tr,is.factor)] %<>% lapply(as.numeric)
rv <- "Diff" # Name of response variable
req.packages <- c("caret","doParallel","iterators","parallel","foreach") # [package dependencies]
  startPkgs <- Vectorize(FUN=function(pkg){suppressPackageStartupMessages(library(pkg,character.only = T))})
  startPkgs(req.packages)
cl <- makeCluster(detectCores()-1)
  registerDoParallel(cl)
  getDoParWorkers()
  sysT.mod <- system.time({ #[model name]
  data.train <- caret::createDataPartition(data.tr[[rv]], times = 1, p=.85) #[Data] & [y-var]
  data.train <- caret::trainControl(method="repeatedcv",
                             index=data.train, 
                             number=10,
                             repeats=1, 
                             search = "grid",
                             allowParallel = T,
                             returnData = F,
                             classProbs=T, 
                             savePredictions = "final",
                             returnResamp = "final")
  form <- as.formula(paste0(rv," ~ .")) #[y-var]
  
  mod <- caretEnsemble::caretList(form = form, # [model name]
                                       data = data.tr,
                                       trControl = data.train,
                                       metric="RMSE",
                                       methodList = c("avNNet","gamSpline","kknn"), #[method list]
                                       tuneList = list("avNNEt"=caretEnsemble::caretModelSpec(
                                         method="avNNet", tuneLength = 10),"gamSpline"=caretEnsemble::caretModelSpec(
                                         method="gamSpline", tuneLength = 10),"kknn"=caretEnsemble::caretModelSpec(
                                         method="kknn", tuneLength = 10)))
  stopCluster(cl);registerDoSEQ()
  })
  
lapply(mod,purrr::pluck,"results","MAE") %>% lapply(mean)
# avNNet performes the best
caret::confusionMatrix(sign(mod[["gamSpline"]][["pred"]]$pred) %>% as.factor,sign(mod[["gamSpline"]][["pred"]]$obs) %>% as.factor)
mod
```

```{r 'Try Classification'}
diff2fac <- function(Diff){
  if(is.numeric(Diff)){x <- as.factor(sign(Diff))}else{
Diff %<>% forcats::fct_recode('n'='-1','z'='0','p'='1')}}
data.tr %<>% mutate(sDiff=diff2fac(sDiff)) 
rv <- "sDiff"
cl <- makeCluster(detectCores()-1)
  registerDoParallel(cl)
  getDoParWorkers()
  sysT.mod <- system.time({ #[model name]
  data.train <- caret::createDataPartition(data.tr[[rv]], times = 1, p=.85) #[Data] & [y-var]
  data.train <- caret::trainControl(method="repeatedcv",
                             index=data.train, 
                             number=10,
                             repeats=1, 
                             search = "grid",
                             allowParallel = T,
                             returnData = F,
                             classProbs=T, 
                             savePredictions = "final",
                             returnResamp = "final")
  form <- as.formula(paste0(rv," ~ .")) #[y-var]
  
  mod <- caretEnsemble::caretList(form = form, # [model name]
                                       data = data.tr,
                                       trControl = data.train,
                                       metric="Accuracy",
                                       methodList = c("avNNet","svmRadial","svmLinear","kknn","C5.0","LogitBoost"), #[method list]
                                       tuneList = list("avNNEt"=caretEnsemble::caretModelSpec(
                                         method="avNNet", tuneLength = 10),"svmRadial"=caretEnsemble::caretModelSpec(
                                         method="svmRadial", tuneLength = 10),"svmLinear"=caretEnsemble::caretModelSpec(
                                         method="svmLinear", tuneLength = 10),
    "kknn"=caretEnsemble::caretModelSpec(
                                         method="kknn", tuneLength = 10),
    "C5.0"=caretEnsemble::caretModelSpec(
                                         method="C5.0", tuneLength = 10),
    "LogitBoost"=caretEnsemble::caretModelSpec(
                                         method="LogitBoost", tuneLength = 10)
    ))
  stopCluster(cl);registerDoSEQ()
  })
  lapply(mod,purrr::pluck,"results","Accuracy") %>% lapply(mean)
  unloadPkgs <- Vectorize(FUN=function(pkg){detach(pkg,character.only = T)})
  unloadPkgs(req.packages)
```
<p>Which stocks to invest in, how much to allocate to these stocks, which stocks are trending and which are oscillating, where to set your trailing stop-loss, e.t.c.</p> <a href="https://www.quora.com/Can-machine-learning-algorithms-models-predict-the-stock-prices-If-yes-which-are-the-best-machine-learning-algorithm-models-to-predict-the-stock-prices">Source</a>

<h3>Performance detection</h3>
<p>RV is sign of the cumsum of next day hourly</p>
<ol>
  <li>Basic LM Time ~ Close - slope indicates trend</li>
  <li>Add indicators implied in article + all indicators already functionalized</li>
  <li>Create derived for DIn, DIp subtract(DIp,DIn)</li>
  <li>Moving averages across 4 durations each: day, week, 28 days, quarter</li>
</ol>
<h3>Knn for selection</h3>
<ol>
  <li>Vector of symbol names</li>
  <li>Pull data for each into nested list object</li>
  <li>Add indicators</li>
  <li>Normalize all</li>
  <li>Take 5 most recent rows (head) and rbind</li>
  <li>Select and remove one symbol and data, and run knn prediction on the rest to find 5 predictions for which is the nearest neighbors. </li>
  <li>Take the tie break vote for which stock is performing similarly </li>
</ol>
<hr>
<p>First step, create response variables of varying time windows for use in predicting validity of trading signals.</p>
<table>
  <tbody>
    <tr valign="top">
      <td><code>rv</code></td>
      <td>as a character vector
        <p><em>Required</em> The name of the response variable in the dataset for which windowed gains/losses are to be computed <em>as a character vector</em></p>
      </td>
    <tr valign="top">
      <td><code>wind</code></td>
      <td>
        <p><em>Required</em> The number of periods in the window for which the gain/loss will be computed, <em>can be a positive integer or a vector of postive integers</em></p>
      </td>
    </tr>
    <tr valign="top">
      <td><code>dat</code></td>
      <td>
        <p><em>Required</em> The dataset as a data frame or tibble on which these windowed gains/losses will be computed</p>
      </td>
    </tr>
  </tbody>
</table>





# KNN Selector
```{r 'knn to select similar stocks'}
# ----------------------- Thu Apr 26 18:30:53 2018 ------------------------#
# 

```
```{r 'Add ATR as Pct for Comparison'}
##
```

```{r 'Windowed Predictor Function'}
# ----------------------- Thu Apr 26 18:30:05 2018 ------------------------#
# Stalled till we find a combination of predictors and algorithms with some degree o accuracy

library(caret)
library(caretEnsemble)

windowedmL <- function(df,wind=100,rv="Diff",...){ # df is data, wind= window, rv =  response variable name (character), ... = vectors of indicator columns (name as used in mutate)
  alli <- 101:nrow(df)
  data.tr <- select(df,...)
  cl <- makeCluster(detectCores()-1)
  registerDoParallel(cl)
  getDoParWorkers()
  sapply(alli,data.tr=data.tr,rv=rv,function(i,data.tr,rv){
    ind <- rev(seq(i,i-wind))
    data.tr <- data.tr[ind,]
    req.packages <- c("caret","doParallel","iterators","parallel","foreach") # [package dependencies]
  startPkgs <- Vectorize(FUN=function(pkg){suppressPackageStartupMessages(library(pkg,character.only = T))})
  startPkgs(req.packages)
  sysT.mod <- system.time({ #[model name]
  data.train <- caret::createDataPartition(data.tr[[rv]], times = 1, p=.85) #[Data] & [y-var]
  data.train <- caret::trainControl(method="repeatedcv",
                             index=data.train, 
                             number=10,
                             repeats=1, 
                             search = "grid",
                             allowParallel = T,
                             returnData = F,
                             summaryFunction=caret::twoClassSummary,
                             classProbs=T, 
                             savePredictions = "final",
                             returnResamp = "final")
  form <- as.formula(paste0("Diff"," ~ .")) #[y-var]
  
  mod <- caretEnsemble::caretList(form = form, # [model name]
                                       data = data.tr,
                                       trControl = data.train,
                                       metric="RMSE",
                                       methodList = c("bstSm","avNNet","gamSpline","kknn"), #[method list]
                                       tuneList = list("bstSm"=caretEnsemble::caretModelSpec( #[method specs]
                                         method="bstSm", tuneLength = 10),"avNNEt"=caretEnsemble::caretModelSpec(
                                         method="avNNet", tuneLength = 10),"gamSpline"=caretEnsemble::caretModelSpec(
                                         method="gamSpline", tuneLength = 10),"kknn"=caretEnsemble::caretModelSpec(
                                         method="kknn", tuneLength = 10)))
  return(list(sysT.mod,mod))
  })

  })
  
  

  stopCluster(cl):registerDoSEQ()
  unloadPkgs <- Vectorize(FUN=function(pkg){detach(pkg,character.only = T)})
  unloadPkgs(req.packages)
  
}
```


```{r 'Graph SAR Indicator',fig.dim=c(10.5,4)}
library(tidyquant)
lapply(seq_along(TS.adxsar),TS=TS.adxsar,FUN=function(i,TS){
  nm <- names(TS)[i]
  TS[[i]] %>% filter(time > lubridate::ymd("2017-05-01") & time < lubridate::ymd("2017-05-31")) %>% ggplot(data=.,aes(x = time, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close),size=.3) +
    geom_point(aes(y=sar,shape=sar.i),size=.7)+
    geom_vline(data=function(x){x %>% filter(Action == "buy")},aes(xintercept=time),color="blue")+
  geom_vline(data=function(x){x %>% filter(Action == "sell")},aes(xintercept=time),color="red")+
    labs(title = "GOOG", 
         y = "Closing Price", x = "Time")+
  theme_tq()+
  scale_shape_manual(values=c(buy=24,sell=25,none=20))
  #ggplot2::ggsave(filename=paste0(nm,"ts.pdf"),plot=last_plot(), path="C:\\Users\\Stephen\\Documents\\Northeastern\\Git\\ppua5302\\Project 3\\Plots",device = "pdf",width = 10.5/2, height = 4, units = "in")
})
TS.adxsar$GOOG%>% filter(time > lubridate::ymd("2017-05-01") & time < lubridate::ymd("2017-05-31")) %>% ggplot(data=.,aes(x = time, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close),size=.3) +
    geom_point(aes(y=sar,shape=sar.i),size=.7)+
    geom_vline(data=function(x){x %>% filter(Action == "buy")},aes(xintercept=time),color="blue")+
  geom_vline(data=function(x){x %>% filter(Action == "sell")},aes(xintercept=time),color="red")+
    labs(title = "GOOG", 
         y = "Closing Price", x = "Time")+
  theme_tq()+
  scale_shape_manual(values=c(buy=24,sell=25,none=20))
```


```{r 'ADX Signal Stockcharts'}
# ----------------------- Tue Apr 24 09:07:39 2018 ------------------------#
# 

ADX <- TS.indicators[["TSLA"]][128,]$ADX;DX <- TS.indicators[["TSLA"]][128,]$DX;SMA <- TS.indicators[["TSLA"]][128,]$SMA28;DIp <- TS.indicators[["TSLA"]][128,]$DIp;DIn <- TS.indicators[["TSLA"]][128,]$DIn;close <- TS.indicators[["TSLA"]][128,]$close
siADX <- function(ADX,DX,DIp,DIn,close,verbose=F){lgl <- rep(F,3)
names(lgl) <- c("ADX","DI","Close")
  if(is.na(DIp)|is.na(SMA)){return(NA)}else if(is.na(ADX)){ADX <- DX}else {ADX}
  if(verbose==T)print(paste(ADX,DX,SMA,DIp,DIn,close,sep=","))
  if(DIp >= DIn){
  lgl[1] <- ADX > 20
  if(verbose==T)print(lgl)# ADX is above 20
  lgl[2] <- DIp > DIn
  if(verbose==T)print(lgl)
  lgl[3] <- close > SMA
  if(verbose==T)print(lgl)
  ind <- which(lgl)
  if(verbose==T)print(ind)
  if(any(names(ind) %in% "Close")){ind[["Close"]] <- ind[["Close"]] + .5}
  out <- sum(ind * .5 )}else{
    lgl[1] <- T
    lgl[2] <- DIp < DIn
  lgl[3] <- close < SMA
  ind <- which(lgl)
  if(any(names(ind) %in% "Close")){ind[["Close"]] <- ind[["Close"]] + .5}
  out <- sum(ind * .5)* -1}
  return(out)
}
siADX(ADX,DX,SMA,DIp,DIn,close,verbose=T)
siL_ADX <- function(ADX,DX,SMA,DIp,DIn,close,verbose=F){lgl <- rep(F,3)
  names(lgl) <- c("ADX","DI","Close")
  if(is.na(DIp)|is.na(SMA)){return(NA)}else if(is.na(ADX)){ADX <- DX}else {ADX}
  out <- DIp >= DIn & ADX > 20 & DIp > DIn & close > SMA
  return(out)
  }
```
```{r}

# Add MACD - more efficient

TS.indicators <- lapply(TS.indicators,FUN=function(l){
  cbind(l,TTR::TDI(l[,c("close")],n=7,multiple=4))
})

TS.indicators <- lapply(TS.indicators,FUN=function(l){
  cbind(l,RSI7=TTR::RSI(l[,c("close")],n=7),RSI14=TTR::RSI(l[,c("close")],n=14))
})


# ----------------------- Thu Apr 19 06:08:57 2018 ------------------------#
# Now we have some solid indicators to work with.
lapply(TS.indicators,FUN=function(l){ggplot(data = l,mapping=aes(x=date))+
  geom_errorbar(aes(ymin=low,ymax=high),color='blue')+
    geom_point(aes(y=`1_10.sar`,color=`1_10.ind`),size=.2,shape=24,alpha=.5)+
    geom_point(aes(y=`2_20.sar`,color=`2_20.ind`),size=.2,shape=8)})
```




```{r 'Apply ADX Indicator'}
TS.indicators %<>%  lapply(FUN=function(l){
  l %<>% rowwise %>% mutate(ADX.ind=siADX(ADX,DX,SMA28,DIp,DIn,close))
})
## 4/20/2018 9:32:05 AM
# Create a buy or sell signal based on each indicator. When the come into agreement, master signal column shows buy/sell signal. 
# buy signal - agreement on indicators (possibly also price < previous sell price)
# sell signal - agreement on indicators - weight given to SAR (sensitivity refinement necessary), if sell price * .8 (tax) - fee > 0 then sell and record transactions
# rebuy signal - need to develop specific indicators attuned to price recovery (as longer term indicators with greater lag might not give agreement to buy signal in these instances.) The MACD, PR20, and SAR might be the best for this measure.
#Automatically records transaction in 2nd DF with all columns necessary for tax reporting.
```

```{r 'Develop RSI Indicator'}
# ----------------------- Tue Apr 24 11:26:17 2018 ------------------------#
# Needs refinemnt of factor indicators

siRSI <- function(RSI,SMA28,SMA100,close) {
  #Oversold, Overbought, Bear, Bull,Support,Resistance
  if(is.na(SMA28)){return(NA)}else if(is.na(SMA100)){SMA <- SMA28}else {SMA <- SMA100}
  
  if(close > SMA){out <- "Up"
  if(RSI >= 50){out <- paste0(out,"St")}else if(RSI <= 40 & RSI > 30){out <- paste0(out,"We")}else if(RSI <= 30){out <- paste0(out,"OS")}else if(RSI < 50 & RSI > 40){paste0(out,"Su")}
  }else if(close < SMA){out <- "Do"
  if(RSI >= 50){out <- paste0(out,"St")}else if(RSI <= 40 & RSI > 30){out <- paste0(out,"We")}else if(RSI >= 70){out <- paste0(out,"OB")}else if(RSI < 50 & RSI > 40){paste0(out,"Re")}
  }
  return(out)
}
```

```{r 'Apply RSI Indicator'}
TS.indicators %<>%  lapply(FUN=function(l){
  l %<>% rowwise %>%  mutate(RSI.ind=siRSI(RSI=RSI14,SMA28=SMA28,SMA100=SMA100,close=close))
})

```

```{r 'TDI Indicator'}
siTDI <- function(tdi,di){
  out <- ifelse(sign(tdi) > 0 & sign(di) < 0,T,F)
}
```
```{r 'Apply TDI'}
TS.indicators %<>%  lapply(FUN=function(l){
  l %<>% rowwise %>%  mutate(TDI.ind=siTDI(tdi=tdi,di=di))
})
```

```{r 'Buy Sell Indicator'}
# ----------------------- Tue Apr 24 14:11:22 2018 ------------------------#
# Not effective, buy threshold is likely too high

siBS <- function(sar.ind1,sar.ind2,adx.ind,rsi.ind,macd.ind,tdi.ind,verbose=F) {lgl <- rep(F,5)

  formals(siBS) %<>% lapply(FUN=function(x){if(is.na(x)){x <- F}})
  
  
  lgl[["v.sar"]] <- ifelse(sar.ind1 == "rise",T,F)
  if(verbose==T)print(lgl)
  lgl[["v.adx"]] <- ifelse(adx.ind > 2,T,F)
  if(verbose==T)print(lgl)
  lgl[["v.rsi"]] <- stringr::str_detect(rsi.ind,"UpSt")
 if(verbose==T)print(lgl)
  lgl[["v.macd"]] <- ifelse(macd.ind > 0,T,F)
  if(verbose==T)print(lgl)
  lgl[["v.tdi"]] <- tdi.ind
  if(verbose==T)print(lgl)
  
  out <- if(sum(lgl,na.rm=T)/5 > .5){out <- "buy"}else if(sar.ind1 == "fall" & sar.ind2 == "fall"){out <- "sell"}else {out <- "none"}
   
  return(out)
}
# ----------------------- Tue Ap,r 24 14:11:42 2018 ------------------------#
# Take 2, just SAR & ADX
siBS.SAR <- function(sar1,sar2,adx.ind){
  if(is.na(sar1) | is.na(sar2) | is.na(adx.ind)){return("sell")}
  if(sar1 == "rise" & sar2 == "rise" & adx.ind > 2){out <- "buy"}else if(sar1 == "fall" & sar2 == "fall"){out <- "sell"}else {out <- "none"}
  return(out)
}


```
```{r 'Apply Buy Sell Indicator'}
TS.indicators %<>%  lapply(FUN=function(l){
  l %<>% rowwise %>%  mutate(BS.ind=siBS(sar.ind1=`2_20.ind`,sar.ind2=`1_10.ind`,adx.ind=ADX.ind,rsi.ind=RSI.ind,macd.ind=macd,tdi.ind=TDI.ind,verbose=F))
})
TS.indicators %<>%  lapply(FUN=function(l){
  l %<>% rowwise %>%  mutate(BS.ind=siBS.SAR(sar1=`2_20.ind`,sar2=`1_10.ind`,adx.ind=ADX.ind))
})
```

```{r 'Backtest BS Indicator for 2017'}
TS.GOOG <- TS.indicators[["GOOG"]][lubridate::year(TS.indicators[["GOOG"]]$date) == 2017,]
subtract(TS.GOOG[TS.GOOG$date == {TS.GOOG$date %>% max},]$close,TS.GOOG[TS.GOOG$date == {TS.GOOG$date %>% min},]$close) # Overall growth during 2017
# which(TS.GOOG$BS.ind == "buy")
# which(TS.GOOG$BS.ind == "buy")[which(diff(which(TS.GOOG$BS.ind == "buy")) > 1)] 
# which(TS.GOOG$BS.ind == "sell")
# which(TS.GOOG$BS.ind == "sell")[which(diff(which(TS.GOOG$BS.ind == "sell")) > 1)]
cps <- rle(TS.GOOG$BS.ind)
ind <- cumsum(cps$lengths)+1
df.Action <- data.frame(Action=ifelse(cps$values=="sell","buy","sell"),Index=ind)
df.Action %<>% mutate(Date=TS.GOOG[ind,]$date,Price=TS.GOOG[ind,]$close)
{df.Action[df.Action$Action == "buy",]-df.Action[df.Action$Action == "sell",]} %>% .$Price %>% sum(na.rm = T)
```
Citations
Data provided for free by <a href="https://iextrading.com/developer" target="_blank">IEX</a>. View <a href="https://iextrading.com/api-exhibit-a/" target="_blank">IEX’s Terms of Use</a>.


### Appendix
```{r 'Windowed Response Variable Fn'}
winRV <- function(rv=NULL,wind=7,dat=NULL) {
  if(!is.vector(wind)|!is.double(wind)){stop("Window must be an integer or a vector of integers")}else {len <- 1:{length(wind)}}
  if(is.null(rv)|is.null(dat)){stop("All variables are required!")}
  # ----------------------- Fri May 04 08:54:09 2018 ------------------------#
  # Primary computation
  tl <- length(dat[[rv]]) # Length of the data as a window limiter
  rvmat <- matrix(nrow = tl, ncol = length(wind)*3,data=rep(NA,tl * length(wind)*3))
  for (i in seq_along(wind)) {
    wi <- wind[i]
    for (r in seq_along(dat[[rv]])) {
      if(r + wi > tl){win <- r:tl}else {win <- r:{r+wi}}# Create Window
      
      rvmat[r,{i*3-2}] <- dat[[rv]][max(win)]-dat[[rv]][min(win)]# Find the Difference for the window and add it to the appropriate matrix column
      
      rvmat[r,{i*3-1}] <- sign(rvmat[r,{i*3-2}]) # Find the sign of the difference and add it to the appropriate matrix column
      rvmat[r,{i*3}] <- (max(dat[[rv]][win])-min(dat[[rv]][win])) * ifelse(which.min(dat[[rv]][win]) > which.max(dat[[rv]][win]),-1,1) # Find the max gain/loss possible for that time period and add it to the appropriate matrix column
      
    }
  }
  colnames(rvmat) <- t(sapply(paste0("y.",c("Diff","Sign","MaxGL")),paste,wind,sep="."))
    cbind(dat,rvmat)
           
       
      
  
}
winRV(rv = "close",wind = wind, dat = Positions_ts$GOOG)
```
```{r 'Finam Hourly Data'}
# Pull Data Deprecated 
TS.adxsar <- POS$Symbol %>% as.character %>% sapply(FUN=function(sym){QuantTools::get_finam_data(sym,from=lubridate::mdy("01-01-2015"), to=lubridate::now(), period = "hour")},simplify = F)
# TS.adxsar %<>% lapply(FUN=function(l){
#   l <- l[,c(1:6)]
# }) # Remove ADX
# Add ADX
TS.adxsar %<>%  lapply(FUN=function(l){
  cbind(l,TTR::ADX(l[,c("high","low","close")],n=20)) %>% rename(ADXv=ADX)
})

```
```{r 'YTD 2018 Linear Regression Models'}
lms <- lapply(TS.adxsar, function(l){
  if(str_detect(names(l),"time") == T){
  l <- l %>% mutate("date" = lubridate::as_date(time)) %>% group_by(date) %>%  summarize_all(.funs = mean) %>% mutate_if(.predicate = is.numeric, .funs = scale)
  }
  ytd  <- l %>% filter(date > lubridate::ymd("2018-01-01"))
  glm(close ~ date, data = ytd, family = "gaussian")
})
lapply(lms,summary) %>% lapply(purrr::pluck("coefficients"))
```
```{r 'Apply Percent Rise'}
Positions_ts %<>% lapply(tp = timeperiods,verbose=F,FUN=function(l,tp,verbose){
  
    
  # ----------------------- Fri Aug 17 16:06:50 2018 ------------------------#
  # For debug
  # tp <- timeperiods
  # l <- Positions_ts$GOOG
  pRises <- sapply(tp,l=l,verbose=verbose,FUN = function(x,l,verbose){
    pRise(l$close,x,verbose)
  })
  l <- cbind(l,pRises)
  colIndexes<- seq({ncol(l)-length(tp)+1},ncol(l))
  colNames <- sapply(tp,FUN = function(x){
    paste0("pRise.", x)
  })
  names(l)[colIndexes] <- colNames
  return(l)
})
```
```{r 'Apply sDxts'}
Positions_ts %<>% lapply(tp = timeperiods,verbose=F,FUN=function(l,tp,verbose){
  # ----------------------- Fri Aug 17 16:06:50 2018 ------------------------#
  # For debug
  # tp <- timeperiods
  # l <- Positions_ts$GOOG
  
  l <- cbind(l,sDs)
  colIndexes<- seq({ncol(l)-length(tp)+1},ncol(l))
  colNames <- sapply(tp,FUN = function(x){
    paste0("sd.", x)
  })
  names(l)[colIndexes] <- colNames
  return(l)
})
```
```{r 'Apply Percent Change'}
Positions_ts %>% lapply(tp = timeperiods,verbose = F,FUN = function(l,tp,verbose){
  # ----------------------- Fri Aug 17 16:06:50 2018 ------------------------#
  # For debug
  # tp <- timeperiods
  # l <- Positions_ts$GOOG
  pChanges <- sapply(tp,l=l,verbose=verbose,FUN = function(x,l,verbose){
    pChange(l$close,x,verbose)
  })
  l <- cbind(l,pChanges)
  colIndexes<- seq({ncol(l)-length(tp)+1},ncol(l))
  colNames <- sapply(tp,FUN = function(x){
    paste0("pChange.", x)
  })
  names(l)[colIndexes] <- colNames
  return(l)
})
```

#Appendix
## ADX & SAR Algorithm from Finance for Freelancers
```{r 'Combine SAR & ADX as Indicator'}
ADXSAR.i <- function(adx.ind=adx.i,sar.ind=sar.i,wind=3) { # Both indicators and a window
  vout <- sapply(seq_along(adx.ind),adx.ind=adx.ind,sar.ind=sar.ind,wind=wind,FUN=function(i,adx.ind,sar.ind,wind){ind <- seq(i,i+wind,by=1)
    if(adx.ind[i] == "buy" & any(sar.ind[ind] %in% "buy")){out <- "buy"}else if(sar.ind[i]=="sell"){out <- "sell"}
  return(out)
  })
  return(vout)
}
# For Debugging
adx.i <- TS.adxsar[["GOOG"]]$adx.i
sar.i <- TS.adxsar[["GOOG"]]$sar.i
```
```{r 'Apply ADXSAR Indicator'}
TS.adxsar  %<>% lapply(FUN=function(l){
  if(any(names(l) %in% "ADXSAR.i")){l %<>% select(- ADXSAR.i)}
  l %>% mutate(ADXSAR.i=ADXSAR.i(sar.ind=sar.i,adx.ind=adx.i))
})
```
```{r 'Compute Buy and Sell Points'}
# ----------------------- Tue Apr 24 19:10:12 2018 ------------------------#
# ADX needs built in stoploss with diff

TS.adxsar %<>% lapply(FUN=function(l){

bs.rle <- l$ADXSAR.i %>% rle
ind <- cumsum(bs.rle$lengths)+1
ind[length(ind)] <- ind[length(ind)]-1
b.ind <- which(bs.rle$values == "sell") # The buy indexes come when the rle value changes, so a buy is indicated by sell
s.ind <- which(bs.rle$values == "buy") # and vice versa
l %<>% mutate(Action=NA)
l$Action[ind[s.ind]] <- rep("sell",length(s.ind))
l$Action[ind[b.ind]] <- rep("buy",length(b.ind))

# df <- data.frame(action=c(rep("sell",length(s.ind)),rep("buy",length(b.ind))),indices=c(ind[s.ind],ind[b.ind])) 
# df$time <- .y$time[df$indices]
# df$close <- .y$close[df$indices]
# df.Action <- data.frame(Action=ifelse(cps$values=="sell","buy","sell"),Index=ind)
# df.Action %<>% mutate(Date=TS.GOOG[ind,]$date,Price=TS.GOOG[ind,]$close)
# {df.Action[df.Action$Action == "buy",]-df.Action[df.Action$Action == "sell",]} %>% .$Price %>% sum(na.rm = T)

return(l)
})
```

```{r 'Compare to Buy and Hold'}
{TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "sell","close"] - TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "buy","close"]} %>% sum(na.rm = T)
{TS.adxsar.signals$GOOG[which.max(TS.adxsar.signals$GOOG$time),"close"] - TS.adxsar.signals$GOOG[which.min(TS.adxsar.signals$GOOG$time),"close"]}
purrr::map2(.x = TS.adxsar, T)
# ----------------------- Tue Apr 24 23:10:50 2018 ------------------------#
# Close - still no better than buy and hold. Needs a trailing stop mechanism. Assign % stop loss to window mean(close[i:i-6]-low[i:i-6])/close
```
```{r 'Patterns in ADX SAR Algo'}

# ----------------------- Thu Apr 26 11:36:55 2018 ------------------------#
# Join the buy points with the loss or gain per period and see if there are patterns
{TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "sell","close"] - TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "buy","close"]} %>% length
TS.adxsar$GOOG %>% filter(Action=="buy") %>% select(time,PR,sar,ADXv,DX,Diff,sar.i) %>% cbind(G.L={TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "sell","close"] - TS.adxsar.signals$GOOG[TS.adxsar.signals$GOOG$action == "buy","close"]}) %>% lm(G.L ~ ., data=.) %>% summary

```


## Add Simple Moving Averages
<p>The function below adds moving averages for 7 hour periods (1 day), 35 hr periods (1 week), 140 hr periods (one moon cycle), and 420 hr periods (a financial quarter). All of these values are obviously rough estimates as they are absolute periods and do not take into account holidays.</p>
```{r 'Add SMA Iterations'}
TS.adxsar %>% lapply(ns=c(dy=7,wk=35,mc=140,qu=420),FUN=function(l,ns){
  smas <- sapply(ns,close=l[,c("close")],FUN=function(ni,close){
    TTR::SMA(close,n=ni)
  })
  colnames(smas) <- paste("SMA",ns,sep=".")
  cbind(l,smas)
})
```
## Costbasis used for 2018 Taxes
```{r 'Calculating Cost Basis'}
CostBasis18 <- read.csv("~/R/Quant/PortfolioCostBasis2018-07-09.csv")
# ----------------------- Mon Jul 09 19:09:54 2018 ------------------------#
# Clean Data
sapply(CostBasis18, class)
CostBasis18[, c("Date.Sold","Date.Acquired")] %<>% lapply(FUN=lubridate::dmy)
CostBasis18 %<>% rename(`Gain.Loss.Pct` = `Gain.Loss..`)
CostBasis18_Net[, c("Proceeds","Cost.per.Share","Cost","Gain.Loss","Gain.Loss.Pct")] %<>% lapply(.,FUN=function(x)gsub("\\$|\\,|\\%","",x)) %>% lapply(as.numeric)
# ----------------------- Mon Jul 09 20:01:34 2018 ------------------------#
# Portfolio Returns YTD 2018
CostBasis18 %>% group_by(Symbol) %>% summarise_at(.vars = c("Quantity","Cost","Proceeds","Cost.per.Share","Gain.Loss","Gain.Loss.Pct"), .funs = sum) %<>% mutate(Wgt = {Cost/sum(CostBasis18$Cost)}) %>% mutate(W.Yld = Wgt * Gain.Loss.Pct)
```